# Отчет по лаборатоной работе LW1
    Работу выполнил: Козлов Евгений


## Описание задачи:
Научиться создавать простые системы классификации изображений на
основе сверточных нейронных сетей.

### Работа с проектом

В проекте находится файл `lw2.ipynb`, все ячейки оттуда могут (должны по крайней мере) быть выполнены последовательно для повторения эксперимента.

Установка пакетов:

        Внимание! Просьба установить PyTorch самостоятельно. По моему опыту, установка этой библиотеки 
        не всегда проходит сразу и гладко, подозреваю, что все может зависит от операционной системы.


### Данные

Для тестирования моделей был выбран датасет `CIFAR10` из пакета torchvision.
Изначально все выбранные модели были натренированны на другом большом датасете `ImageNet`.
Поэтому `CIFAR10` подходит для тестирования, однако это накладывает ряд сложностей - классы `CIFAR10` и `ImageNet ` различаются, как и по нумерации, так и по смыслу. По этой причине расчет метрик будет производиться вручную,
"на глаз".

### Выбор архитектур моделей

Для тестирования были выбраны модели, предложенные в задании - `AlexNet`, `VGG16`, `ResNet50`

#### AlexNet
* Архитектура: 

        AlexNet - это сверточная нейронная сеть, предложенная в 2012 году Алексом Криспом и Джорджем Хинтоном. Она состоит из 5 сверточных слоев, за которыми следуют 3 полносвязных слоя. В качестве функции активации используется ReLU, а для регуляризации используется метод dropout.
* Особенности:

        Использование ReLU: 
            В отличие от предыдущих моделей, AlexNet использовал активационную функцию ReLU (Rectified Linear Unit), что помогло ускорить сходимость обучения и избежать проблемы затухания градиента.
        Dropout для регуляризации: 
            Для снижения переобучения в сети был использован метод Dropout, который случайным образом "выключает" нейроны в процессе обучения, что помогает модели генерализовать данные лучше.

* Технические характеристики:

        Общее количество слоев: 8 (5 сверточных и 3 полносвязных)
        Количество параметров: около 60 миллионов
        Размер входного изображения: 224x224 пикселя

#### VGG16
* Архитектура: 

        Архитектура AlexNet состоит из 5 сверточных слоев, за которыми следуют 3 полносвязных слоя. Важно отметить, что AlexNet использовал несколько техник, которые стали стандартом в сверточных нейронных сетях, таких как использование ReLU в качестве функции активации и применение метода dropout для регуляризации.
    
* Особенности:

        Глубокая архитектура с маленькими фильтрами: 
            Использование множества сверточных слоев с маленькими фильтрами 3x3 позволяет VGG16 изучать более сложные признаки изображений и улучшает способность обобщения модели.
        Простота архитектуры: 
            Архитектура VGG16 очень проста и однородна, что делает ее легко интерпретируемой и реализуемой.

* Технические характеристики:

        Общее количество слоев: 16 (13 сверточных и 3 полносвязных)
        Количество параметров: около 138 миллионов
        Размер входного изображения: 224x224 пикселя

#### ResNet50

* Архитектура: 

        ResNet50 - это часть семейства нейронных сетей ResNet, которые используют skip-connections (или shortcut connections) для устранения проблемы затухания градиента при обучении глубоких сетей. ResNet50 состоит из 50 слоев, включая 49 блоков residual и один полносвязный слой.

* Особенности:

        Использование skip-connections: 
            Одной из ключевых особенностей ResNet является использование skip-connections, которые позволяют эффективно обучать глубокие сети без проблем с затуханием градиента.
        Блоки residual: 
            Блоки residual позволяют пропускать активации через слой, что позволяет модели обучаться на более глубоких уровнях представлений и улучшает качество классификации.

* Технические характеристики:

        Общее количество слоев: 50
        Количество параметров: около 25 миллионов
        Размер входного изображения: 224x224 пикселя


### Подход к проведению экспериментов

Входные данные: 

        10_000 наборов картинок из датасета CIFAR10 для измерения скорости и ресурсозатратности инференса модели
        50 картинок - для расчета метрик top-1-accuracy и top-5-accuracy


Технические характеристики:

        Процессор: CPU Type	OctalCore AMD Ryzen 9 5900HX, 4400 MHz (44.75 x 98)
        Оперативная память: 16гб 3200 Mhz
        Графический процессор: NVIDIA GeForce RTX 3080 Laptop GPU  (8 GB)

Метрики оценивания:

    Качество моделей также будуте оценитьвася метриками:
    1. top1_accuracy = Количество правильных предсказаний / Общее количество изображений
    2. top5_accuracy = Количество изображений, для которых правильный класс входит в топ-5 предсказанных классов / Общее количество изображений

    Таким  образом мы сможем понять какая модель предсказывает наилучшим образом.
​

### Результаты экспериментов

При использовании модели использовались такие преобразования:

        batch_size = 50
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])


#### AlexNet

    * Скорость работы инференса и ресуры: 
        Average Inference Time per Image: 12.55754566192627 seconds
        Average Memory Consumption per Iteration: 356.775859375 MB

    * Метрики
        top_1_accuracy: 0.06
        top_5_accuracy: 0.14
#### VGG16

    * Скорость работы инференса и ресуры: 
        Average Inference Time per Image: 33.36986756324768 seconds
        Average Memory Consumption per Iteration: 243.17759765625 MB
    * Метрики
        top_1_accuracy: 0.3
        top_5_accuracy: 0.52

#### ResNet50

    * Скорость работы инференса и ресуры: 
        Average Inference Time per Image: 21.47453260421753 seconds
        Average Memory Consumption per Iteration: 349.35625 MB

    * Метрики
        top_1_accuracy: 0.36
        top_5_accuracy: 0.68


Графики:
* График сравнения скоростей инференса:
    <img src="/speed_comp.png">

* График Сравнения затрат по памяти:
    <img src="/mem_comp.png">

* Графики значений метрик от моделей:
    <img src="/stat_plot.png">

### Выводы

Провелась лабораторная работа, в ходе которой было протестированны и оценены 3 модели сверточных нейронных сетей - `AlexNet`, `VGG16`, `ResNet50`. Был произведен замер скорости инференса и потребление памяти, в результате которого архитектура `VGG16` встала на последнее место по скорости, но первое по занимаемым объемам, `AlexNet` и `ResNet50` оказались довольно похожи по эти параметрам.

Наиболее интересной частью работы оказалась оценка работы модели и рассчитывание метрик. Как упоминалось ранее, все модели обучались на датасете `ImageNet` - крайне большой набор данных, состоящий из 10_000 классов. Личная сложность была в сопоставлении классов от модели и классов из тестируемого датасета. Но не смотря на это, выявлены интересные закономерности:

    * Все модели очень хорошо знают собак и почти не знают котов.
    * Машины и грузовкии хорошо/удовлетворительно распознаются в VGG16 и ResNet50, а в AlexNet нет.
    * Лошади, олени, птицы и лягушки практически не распознаются всеми сетями.
    * Самолеты и корабли распознаются не стабильно - предикт сильно завист от фона.

По результатам замеров `ResNet50` показала себя лучшей модели на предикте незнакомого датасета без дообучения

с финальными метриками `top_1_accuracy = 0.36` и `top_5_accuracy = 0.68`, что является хорошим результатом для такого рода задач.


### Используемые материалы
https://pytorch.org/docs/stable/index.html

https://pytorch.org/vision/stable/index.html

https://matplotlib.org/stable/users/index.html

https://seaborn.pydata.org/tutorial.html
